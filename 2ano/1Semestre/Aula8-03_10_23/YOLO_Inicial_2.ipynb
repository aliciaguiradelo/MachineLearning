{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**YOLOv8** √© um novo modelo de vis√£o computacional de √∫ltima gera√ß√£o constru√≠do pela Ultralytics. O modelo YOLOv8 cont√©m suporte pronto para uso para tarefas de detec√ß√£o, classifica√ß√£o e segmenta√ß√£o de objetos, acess√≠vel por meio de um pacote Python, bem como uma interface de linha de comando.\n",
        "\n",
        "Fonte: https://yolov8.com/\n",
        "\n",
        "\n",
        "\n",
        "Documenta√ß√£o e modelos do YOLOv8:\n",
        "\n",
        "https://github.com/ultralytics/ultralytics\n",
        "\n",
        "\n",
        "\n",
        "Sugest√£o de leitura:\n",
        "\n",
        "https://iaexpert.academy/2020/10/13/deteccao-de-objetos-com-yolo-uma-abordagem-moderna/?doing_wp_cron=1696367994.9827990531921386718750"
      ],
      "metadata": {
        "id": "FsacsE3UaD3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instala√ß√£o dos pacotes e das bibliotecas do YOLOv8"
      ],
      "metadata": {
        "id": "X12vIYNcISMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6CZKmgPHVCv"
      },
      "outputs": [],
      "source": [
        "# Instalando a biblioteca do YOLOv8\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o pacote ultralytics\n",
        "import ultralytics"
      ],
      "metadata": {
        "id": "WoQUtqi9HtrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o pacote Pytorch\n",
        "# Documenta√ß√£o: https://pytorch.org/\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "VeoD_X-WH2Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as demais bibliotecas\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "YoXsfVUzIM63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizando a detec√ß√£o\n",
        "\n",
        "A forma mais r√°pida de executar a dete√ßc√£o √© atrav√©s da CLI, conforme pode ver abaixo a sintaxe.\n",
        "\n",
        "Os par√¢metros:\n",
        "* **task** - tarefa, podendo ser detec√ß√£o, segmenta√ß√£o ou classifica√ß√£o\n",
        "* **model** - o modelo que queremos usar. S√£o disponibilizados 5 modelos: YOLOv8n (nano), YOLOv8s (small), YOLOv8m (medium), YOLOv8l (large), YOLOv8x (extra large). Nano √© o mais r√°pido e o menor (menos pesado para rodar), enquanto que o Extra Large (YOLOv8x) √© o mais preciso por√©m mais pesado para rodar, portanto ser√° mais lento.\n",
        "  Para o valor desse par√¢metro, basta informar o nome e ao lado .pt pois √© a extens√£o do modelo treinado em pytorch.\n",
        "\n",
        "* **mode** - basicamente √© o que queremos com o comando. Queremos fazer a detec√ß√£o/infer√™ncia/predi√ß√£o, portanto deixe =predict. Valores aceitos: [train, val, predict, export]\n",
        "\n",
        "* **conf** - o limiar (threshold) que usaremos para filtrar detec√ß√µes \"fracas\". Se a confian√ßa estiver abaixo desse valor, n√£o ser√° considerada. Por padr√£o podemos configurar com um limiar bem baixo (ex: 0.25) e depois aumentar, caso verifique que detectou incorretamente algum objeto.  \n",
        "* **source** - a imagem ou v√≠deo que queremos fazer a detec√ß√£o."
      ],
      "metadata": {
        "id": "qq2Wg3iVRc28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='' save=True"
      ],
      "metadata": {
        "id": "IeeH6qsKI0bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406c75b0-bf12-4a6c-ae21-b45f4113fcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.192 üöÄ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "image 1/1 /content/rrr.jpeg: 448x640 2 persons, 3 bicycles, 102.0ms\n",
            "Speed: 3.5ms preprocess, 102.0ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importante:**\n",
        "- Observe na sa√≠da da c√©lula acima que o resultado da detec√ß√£o ser√° salvo na pasta 'runs/detect/predict/'\n",
        "- Aten√ß√£o ao n√∫mero do 'predict' gerado para passar corretamente o nome na c√©lula abaixo."
      ],
      "metadata": {
        "id": "ySB9UY3uSVUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = cv2.imread('')\n",
        "cv2_imshow(resultado)"
      ],
      "metadata": {
        "id": "ImqRSICRNy6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detec√ß√£o a partir de arquivo externo:\n",
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://ultralytics.com/images/zidane.jpg' save=True"
      ],
      "metadata": {
        "id": "AJbpBhxNLofM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = cv2.imread('/content/runs/detect/predict2/zidane.jpg')\n",
        "cv2_imshow(resultado)"
      ],
      "metadata": {
        "id": "pLJ0Lve3TcnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.4 source='italia.jpg' save=True"
      ],
      "metadata": {
        "id": "m0indQzWV7h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = cv2.imread('/content/runs/detect/predict3/italia.jpg')\n",
        "cv2_imshow(resultado)"
      ],
      "metadata": {
        "id": "fV7VGrfRmvFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.57 source='italia.jpg' save=True"
      ],
      "metadata": {
        "id": "THT0Ih62xlsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = cv2.imread('/content/runs/detect/predict4/italia.jpg')\n",
        "cv2_imshow(resultado)"
      ],
      "metadata": {
        "id": "_xR7BWv2xuJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}